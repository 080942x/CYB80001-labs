{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CYB80001 System Security Project\n",
    "Prepared by **Derui (Derek) Wang**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3B - Fast Gradient Sign and Projected Gradient Descent\n",
    "\n",
    "In this session, we will implement **Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks** based on **Tensorflow** and **Keras**. We will then apply the attacks to a keras classifier to evaluate the attacks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "\n",
    "### Part 1 Using Tensorflow and Keras together\n",
    "\n",
    "1.1 [Load a pre-trained Keras model into a computational graph](#1_1)\n",
    "\n",
    "1.2 [Using a pre-trained Keras model with Tensorflow variables](#1_2)\n",
    "\n",
    "\n",
    "### Part 2 Using Tensorflow to implement FGSM\n",
    "\n",
    "2.1 [Implementing FGSM](#2_1)\n",
    "\n",
    "2.2 [Testing FGSM](#2_2)\n",
    "\n",
    "2.3 [FGSM Exercise](#2_3)\n",
    "\n",
    "### Part 3 Using Tensorflow to implement PGD\n",
    "\n",
    "3.1 [Implementing PGD](#3_1)\n",
    "\n",
    "3.2 [Testing PGD](#3_2)\n",
    "\n",
    "3.3 [PGD Exercise](#3_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1. Using Tensorflow and Keras together \n",
    "\n",
    "Writing attacks means that you need to build your attack algorithms (in Tensorflow) and attack a victim model via its APIs. In this part, we will learn how to integrate your attacks in Tensorflow and a victim classifiers in Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"1_1\"></a>\n",
    "\n",
    "## 1.1 Load a pre-trained Keras model into a computational graph\n",
    "\n",
    "In this section, we will explore how to craft adversarial examples against a DNN classifier. We will use tensorflow to implement the adversarial example attacks.\n",
    "\n",
    "We will use craft adversarial examples of **MNIST** data. We can import the dataset from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# we normalise the pixels to values between 0 and 1\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = np.float32(X_train/255.)\n",
    "X_test = np.float32(X_test/255.)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print('data loaded, training x:{0}, y:{1}; test x:{2}, y{3}.'.format(X_train.shape,\n",
    "                                                                     X_test.shape,\n",
    "                                                                     y_train.shape,\n",
    "                                                                     y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target classifier is a trained one. Therefore, we need to retain the model weights during out attack. How can we do this? Recall that Tensorflow has a graph construction phase and a execution phase. We first need to load the target classifier. \n",
    "\n",
    "For example, we can load `mnist_cnn_model.h5` we trained in the Session 3A using `load_model` function from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "print('Evaluate the loaded model')\n",
    "print(f'Accuracy of the loaded model: {target_classifier.evaluate(X_test, y_test)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a tensorflow graph and use `mnist_cnn_model.h5` as part of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "\n",
    "# buid the keras model into a tensorflow graph\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "output =  target_classifier(x)\n",
    "\n",
    "# execute the graph\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we can run the loaded  `mnist_cnn_model.h5` as a tensorflow graph. You must set the keras session and the tensorflow session to be a same one by using `K.set_session(sess)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"1_2\"></a>\n",
    "\n",
    "## 1.2 Using a pre-trained Keras model with Tensorflow variables\n",
    "\n",
    "Remember that if you have used Tensorflow **variables** in the graph, you must run initialisation after the graph is constructed. \n",
    "\n",
    "In the previous section, there is no Tensorflow variable in the graph. Therefore, we did the initialisation **prior to constructing the graph**. In this part, we will experiment with the cases in which we have Tensorflow variables in the graph.\n",
    "\n",
    "First, we add a variable `z` into the graph. **The following code snippet will intentionally raise an error**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "    \n",
    "# buid the keras model into a tensorflow graph\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "# We use a variable here\n",
    "z = tf.Variable(np.zeros((X_test.shape[0],\n",
    "                          X_test.shape[1],\n",
    "                          X_test.shape[2],\n",
    "                          X_test.shape[3])), dtype=tf.float32, name='tf_variable_z')\n",
    "\n",
    "new_x = tf.clip_by_value(x + z, 0, 1)\n",
    "output =  target_classifier(new_x)\n",
    "\n",
    "# execute the graph\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You recieve an error here. To resolve it, **you must run an initialisation operation after declaring all the variables, right before the learning loop**. Let's add the initialisation operation and run the code again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "    \n",
    "# buid the keras model into a tensorflow graph\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "# We use a variable here\n",
    "z = tf.Variable(np.zeros((X_test.shape[0],\n",
    "                          X_test.shape[1],\n",
    "                          X_test.shape[2],\n",
    "                          X_test.shape[3])), dtype=tf.float32, name='tf_variable_z')\n",
    "\n",
    "new_x = tf.clip_by_value(x + z, 0, 1)\n",
    "output =  target_classifier(new_x)\n",
    "\n",
    "# define an initialisation operation to initialise all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is no error now. However, **the prediction results become incorrect**. This is because the Keras model was initialised as well.\n",
    "\n",
    "Then, **how can we use Tensorflow variables and keras model together?** Let's simply change the order of the initialisation operation and model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (X_test.shape[0],\n",
    "                                X_test.shape[1],\n",
    "                                X_test.shape[2],\n",
    "                                X_test.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "# We use a variable here\n",
    "z = tf.Variable(np.zeros((X_test.shape[0],\n",
    "                          X_test.shape[1],\n",
    "                          X_test.shape[2],\n",
    "                          X_test.shape[3])), dtype=tf.float32, name='tf_variable_z')\n",
    "\n",
    "# Put the init op before loading model\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# load model after the init op\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "new_x = tf.clip_by_value(x + z, 0, 1)\n",
    "\n",
    "# buid the keras model into a tensorflow graph\n",
    "output =  target_classifier(new_x)\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "prediction_on_new_data = sess.run(output, feed_dict={x: X_test, y: y_test})\n",
    "print(f'Predicted labels: {np.argmax(prediction_on_new_data, axis=-1)}')\n",
    "print(f'True labels: {np.argmax(y_test, axis=-1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the correct predictions. **As a conclusion, we can first define an initialisation operation after all Tensorflow variables and then load a Keras model into the graph**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2. Using Tensorflow to implement FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"2_1\"></a>\n",
    "\n",
    "## 2.1 Implementing FGSM\n",
    "We will implement the FGSM attack from scratch in this part.\n",
    "\n",
    "We use `categorical_crossentropy` from Keras, as the adversarial loss function.\n",
    "\n",
    "We first implement **non-targeted** FGSM (the misclassification calss is not specified). In this case, we are going to increase the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# FGSM hyper-parameter\n",
    "eps = 0.15\n",
    "benign_example = X_test[4:5]\n",
    "bening_y = y_test[4:5]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (benign_example.shape[0],\n",
    "                                benign_example.shape[1],\n",
    "                                benign_example.shape[2],\n",
    "                                benign_example.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (bening_y.shape[0], bening_y.shape[1]))\n",
    "\n",
    "# Put the init op before loading model\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# load model after the init op\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "target_classifier.summary()\n",
    "\n",
    "# buid the keras model into a tensorflow graph\n",
    "output =  target_classifier(x)\n",
    "\n",
    "# adversarial loss function\n",
    "loss = K.categorical_crossentropy(output, y)\n",
    "\n",
    "# FGSM attack steps\n",
    "dy_dx, = tf.gradients(loss, x)\n",
    "x_adv = tf.stop_gradient(x + eps * tf.sign(dy_dx))\n",
    "x_adv = tf.clip_by_value(x_adv, 0, 1)\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "fgsm_x = sess.run(x_adv, feed_dict={x: benign_example, y: bening_y})\n",
    "print('Complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fgsm_x` is the adversarial example. We can plot the MNIST example and its FGSM example using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(benign_example.reshape(28,28), cmap='gray')\n",
    "axes[1].imshow(fgsm_x.reshape(28,28), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"2_2\"></a>\n",
    "\n",
    "## 2.2 Testing FGSM\n",
    "\n",
    "We can check the classification results of these two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the examples into the classifier for classification\n",
    "print(f'Keras classifier prediction on the benign example: {np.argmax(target_classifier.predict(benign_example))}')\n",
    "print(f'Keras classifier prediction on the fgsm example: {np.argmax(target_classifier.predict(fgsm_x))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that **the fgsm example is misclassified**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"2_3\"></a>\n",
    "\n",
    "## 2.3 FGSM Exercise\n",
    "\n",
    "We have implemented the **non-targeted FGSM** attack in the above code snippets. \n",
    "\n",
    "As an exercise, you can implement the **targeted FGSM** attack which produces an adversarial example of **digit 4**. You can set the misclassification target to **0**. You can reuse the above code and data in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please complete the exercise in this ocde cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3. Using Tensorflow to implement PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"3_1\"></a>\n",
    "\n",
    "## 3.1 Implementing PGD\n",
    "\n",
    "We will implement the PGD attack from scratch in this part.\n",
    "\n",
    "We use `categorical_crossentropy` from Keras, as the adversarial loss function.\n",
    "\n",
    "We first implement **non-targeted** PGD (the misclassification calss is not specified). We will write the attack steps in a function named `pgd_attack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def pgd_attack(model, x, y, max_iter=1000, clip_min=0., clip_max=1.):\n",
    "    def _cond(x, i):\n",
    "        return tf.less(i, max_iter)\n",
    "\n",
    "    def _body(x, i):\n",
    "        logits = model(x)\n",
    "        loss = K.categorical_crossentropy(logits, y)\n",
    "        dy_dx, = tf.gradients(loss, x)\n",
    "        x = tf.stop_gradient(x + dy_dx)\n",
    "        x = tf.clip_by_value(x, clip_min, clip_max)\n",
    "        return x, i+1\n",
    "    x_adv, i = tf.while_loop(_cond, _body, (x, 0), back_prop=False, name='pgd_attacker')\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then replace the attack steps of the FGSM attack to that of the PGD attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD hyper-parameter\n",
    "MAX_ITER = 5000\n",
    "\n",
    "benign_example = X_test[4:5]\n",
    "bening_y = y_test[4:5]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "#make sure that Keras model use the same session with tensorflow\n",
    "K.set_session(sess)\n",
    "\n",
    "# placeholders to receive input feature matrix and labels\n",
    "x = tf.placeholder(tf.float32, (benign_example.shape[0],\n",
    "                                benign_example.shape[1],\n",
    "                                benign_example.shape[2],\n",
    "                                benign_example.shape[3]))\n",
    "y = tf.placeholder(tf.float32, (bening_y.shape[0], bening_y.shape[1]))\n",
    "\n",
    "# Put the init op before loading model\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# load model after the init op\n",
    "target_classifier = load_model('mnist_cnn_model.h5')\n",
    "#target_classifier.layers.pop()\n",
    "target_classifier.summary()\n",
    "\n",
    "# Attack steps\n",
    "x_adv = pgd_attack(target_classifier, x, y, max_iter=MAX_ITER)\n",
    "\n",
    "# execute the graph\n",
    "# run the initialisation\n",
    "sess.run(init)\n",
    "pgd_x  = sess.run(x_adv, feed_dict={x: benign_example, y: bening_y})\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(benign_example[0].reshape(28,28), cmap='gray')\n",
    "axes[1].imshow(pgd_x[0].reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"3_2\"></a>\n",
    "\n",
    "## 3.2 Testing PGD\n",
    "\n",
    "We can check the classification results of these two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the examples into the classifier for classification\n",
    "print(f'Keras classifier prediction on the benign example: {np.argmax(target_classifier.predict(benign_example))}')\n",
    "print(f'Keras classifier prediction on the fgsm example: {np.argmax(target_classifier.predict(pgd_x))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id = \"3_3\"></a>\n",
    "\n",
    "## 3.3 PGD Exercise\n",
    "\n",
    "We have implemented the **non-targeted PGD** attack in the above code snippets. \n",
    "\n",
    "As an exercise, you can implement the **targeted PGD** attack which produces an adversarial example of **digit 4**. You can set the misclassification target to **0**. You can reuse the above code and data in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please complete the exercise in this ocde cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <div  style=\"text-align:center\">**THE END**</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
