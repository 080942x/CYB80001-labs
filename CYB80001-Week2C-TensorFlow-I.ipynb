{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuralSec/CYB80001-labs/blob/master/CYB80001-Week2C-TensorFlow-I-ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2EuG-JZIec_O"
   },
   "source": [
    "# CYB80001 System Security Project\n",
    "Prepared by **Derui (Derek) Wang**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NeyodAloec_P"
   },
   "source": [
    "# Session 2C - Deep Learning with TensorFlow</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmvMPwM0ec_W"
   },
   "source": [
    "**The purpose of this session is to demonstrate how to work with an open source software library for developing deep neural networks apllications, called TensorFlow. In this practical session, we present the following topics:**\n",
    "\n",
    "1. What is TensorFlow\n",
    "2. How to install TensorFlow\n",
    "3. A quick tour of TensorFlow\n",
    "\n",
    "** References and additional reading and resources**\n",
    "- [Installing Tensorflow on Windows](https://www.tensorflow.org/install/install_windows)\n",
    "- [Tensorflow API documentations](https://www.tensorflow.org/versions/master/api_docs/python/)\n",
    "- [Examples with Tensorflow](https://www.tensorflow.org/versions/master/get_started/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "\n",
    "\n",
    "### Part 1 Getting started with TensorFlow\n",
    "\n",
    "\n",
    "### Part 2 Installation\n",
    "\n",
    "2.1 [How to install TensorFlow](#2_1)\n",
    "\n",
    "2.2 [Testing the installation](#2_2)\n",
    "\n",
    "\n",
    "### Part 3 A quick tour of TensorFlow\n",
    "\n",
    "3.1 [Computational graph](#3_1)\n",
    "\n",
    "3.2 [TensorFlow session](#3_2)\n",
    "\n",
    "\n",
    "### Part 4 More about the graph\n",
    "\n",
    "4.1 [Managing TensorFlow graphs](#4_1)\n",
    "\n",
    "4.2 [Operations (nodes)](#4_2)\n",
    "\n",
    "4.3 [Tensors (edges)](#4_3)\n",
    "\n",
    "\n",
    "###  Part 5 More about the session\n",
    "\n",
    "5.1 [Lifecycle of a node value](#5_1)\n",
    "\n",
    "5.2 [Save and restore models](#5_2)\n",
    "\n",
    "5.3 [Visualize learning curves in TensorBoard](#5_3)\n",
    "\n",
    "\n",
    "### Part 6 Name Scopes (Not mandatory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ud2GTbl9ec_X"
   },
   "source": [
    "Now let's first import the TensorFlow library and load the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pO68szVrec_e"
   },
   "source": [
    "# Part 1. Getting started with TensorFlow\n",
    "\n",
    "TensorFlow is a powerful open source software library for numerical computation, particularly well-suited for large-scale Machine Learning and highly-optimized for Deep Learning. Its basic principle is simple: you first define in Python a graph of computations to perform, and then TensorFlow takes that graph and runs it efficiently using optimized C++ code.\n",
    "\n",
    "TensorFlow has many advanced features. The **coolest** are:\n",
    "* ***Programmer friendly***: The front-end high-level Python API of TensorFlow offers much more flexibility (at the cost of higher complexity) to efficiently create all sorts of computations, including any neural network architecture you can come up with. In addition, there are many higher-level packages that serve as TensorFlow's wrappers to provide even simpler APIs such as TF.Learn ([http://tflearn.org/](http://tflearn.org/), compatible with Scikit-Learn), Keras ([https://keras.io/](https://keras.io/)), to name a few. You can use these APIs to train various types of neural networks in just a few lines of code.\n",
    "* ***Machine learner friendly***: TensorFlow automatically takes care of computing the gradients of the functions you define. This is called automatic differentiating (or `autodiff`).\n",
    "* ***TensorBoard***: TensorFlow also comes with a great visualization tool called *TensorBoard* that allows you to browse through the computation graph, view learning curves, and more. This feature is extremely useful for researchers.\n",
    "* ***Highly-optimized back-end***: TensorFlow includes highly efficient C++ implementations of many machine learning operations, particularly those needed to build neural networks. There is also a C++ API to define your own high-performance operations. * TensorFlow can train a network with millions of parameters on a training set composed of billions of instances with millions of features each.\n",
    "* ***Device switchable***: You can switch between computation on CPU and GPU with one line of code: `tf.device('cpu')` or `tf.device('gpu:x')`.\n",
    "* ***Parallelized and Distributed***: It is possible to break up the graph into several chunks and run them in parallel across multiple CPUs or GPUs. Moreover, TensorFlow also supports distributed computing, so you can train colossal neural networks on humongous training sets in a reasonable amount of time by splitting the computations across hundreds of servers.\n",
    "* ***Cross-platform***: TensorFlow can run not only on Windows, Linux, and macOS, but also on mobile devices, including both iOS and Android.\n",
    "* Last but not least, TensorFlow was developed by **Google Brain** team, and have been being long-term supported and maintained by **Google**. It powers many of Google’s large-scale services, such as Google Cloud Speech, Google Photos, and Google Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZ6l6K3wec_e"
   },
   "source": [
    "# Part 2. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_cwycGjec_k"
   },
   "source": [
    "<a id = \"2_1\"></a>\n",
    "\n",
    "## 2.1 How to install TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO8g52LXec_m"
   },
   "source": [
    "<span style=\"color:blue\">**Step 1.**</span> Install Anaconda (if you have Anaconda installed, you can skip this step)\n",
    "  \n",
    "<span style=\"color:blue\">**Step 2.**</span> Install TensorFlow on Windows with CPU:\n",
    "**`pip install --ignore-installed --upgrade tensorflow`**\n",
    "\n",
    "If you want to install Tensorflow on other OSs and/or with GPU, you can follow the instructions in [this guide](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmYLCRKvec_s"
   },
   "source": [
    "<a id = \"2_2\"></a>\n",
    "\n",
    "## 2.2 Testing the installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6IGj0_9ec_t"
   },
   "source": [
    "<span style=\"color:blue\">**Step 1.**</span> Import TensorFlow and print out the version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCveMArxec_v",
    "outputId": "26efc9de-1adb-45d7-d743-db28e16d66bb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPu48AyKec__"
   },
   "source": [
    "<span style=\"color:blue\">**Step 2.**</span> Test TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ecx6a8jec__",
    "outputId": "3704e5ac-5028-42f4-b574-27ae3f8e2f8d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    op1 = tf.constant(5., name='a')\n",
    "    op2 = tf.constant(2., name='b')\n",
    "    op3 = tf.multiply(op1, op2, name='c')\n",
    "\n",
    "log_dir = 'tf_logs/example00'\n",
    "writer = tf.summary.FileWriter(log_dir, g)  # write the graph to a event file in folder log_dir\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(sess.run(op3))\n",
    "\n",
    "writer.close()  # Close the writer when you're done with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3IS82bXedAC"
   },
   "source": [
    "* Now open Anaconda prompt and change to the directory that contains your notebook (and the `tf_logs` folder) then type:  \n",
    "`tensorboard --logdir=tf_logs/example00 --host=127.0.0.1`\n",
    "\n",
    "* The terminal will display: \"Tensorboard <version> at http://127.0.0.1:6006 (Press CTRL+C to quit)\".\n",
    "* Open your browser and go to http://127.0.0.1:6006/. Click \"Graphs\" and you will see:  \n",
    "\n",
    "<img src=\"imgs/TensorBoard.jpg\" width=800>\n",
    "\n",
    "* If you want to open tensorboard at **another** port such as 9009, type the following in the terminal:  \n",
    "`tensorboard --logdir='tf_logs/example00' --host=127.0.0.1 --port=9009`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrEpC8ioedAD"
   },
   "source": [
    "# Part 3. A quick tour of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qp25dNxtedAE"
   },
   "source": [
    "After Tensorflow is installed, we can import the TensorFlow as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7GJW6eRedAE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0MdjvcIedAG"
   },
   "source": [
    "Let's review the very simple piece of code we just saw in II.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IP6iROHnedAH",
    "outputId": "afdd6b5a-e938-4f0a-c7ef-8ecbe4ffe12e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Building the computational graph\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    op1 = tf.constant(5., name='a')\n",
    "    op2 = tf.constant(2., name='b')\n",
    "    op3 = tf.multiply(op1, op2, name='c')\n",
    "    print(op3)  # What is the type of c?\n",
    "\n",
    "# Step 2: Running the computational graph \n",
    "with tf.Session(graph=g) as sess:\n",
    "    res = sess.run(op3)\n",
    "    print(res)\n",
    "    print(type(res)) # What is the type of res?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAWfabhJedAJ"
   },
   "source": [
    "As you can see, a TensorFlow program consists of two consecutive steps. \n",
    "1. Building a computational graph.\n",
    "2. Running the computational graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AR0-1RfRedAK"
   },
   "source": [
    "<a id = \"3_1\"></a>\n",
    "\n",
    "## 3.1. Computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UyvxiAOedAL"
   },
   "source": [
    "You have already seen the computational graph generated from Step 1.  \n",
    "<img src=\"imgs/TensorBoard.jpg?raw=1\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AiHSGKF6edAM"
   },
   "source": [
    "A TensorFlow computational graph is a directed graph that defines the data flow of a computation.\n",
    "In the graph, each node represents a *TensorFlow Operation* and each edge represent a *Tensor* that is the output of the edge's source node and the input for the edge's target node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTENUNAaedAM"
   },
   "source": [
    "<a id = \"3_2\"></a>\n",
    "\n",
    "## 3.2. TensorFlow session\n",
    "\n",
    "To evaluate this graph, you need to open a TensorFlow ***session*** and use it to initialize the variables and run the computation steps. A TensorFlow session takes care of placing the operations onto devices such as CPUs and GPUs and running them, and it holds all the variable values.\n",
    "\n",
    "In distributed TensorFlow, variable values are stored on the servers instead of the session.\n",
    "\n",
    "The following code creates a session, run the operation `op3` and then closes the session (which frees up resources):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzAujLZjedAN"
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    res = sess.run(op3)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PO86-pMXedAP"
   },
   "source": [
    "As we just saw, you do not need to explictly run the operations `op1` and `op2`. TensorFlow will find all the operations that `op3` depends on and run those operations first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j71G1cgnedAQ"
   },
   "source": [
    "Also `sess.run(op3)` is equivalent to `op3.eval(session=sess)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VYSu7XXedAQ"
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    res = op3.eval()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enqegjFfedAS"
   },
   "source": [
    "# Part 4. More about the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8cCZjN6edAS"
   },
   "source": [
    "<a id = \"4_1\"></a>\n",
    "\n",
    "## 4.1. Managing TensorFlow graphs\n",
    "\n",
    "Any node you create is automatically added to the default graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4L8UwDmOedAT",
    "outputId": "47092cc0-84d0-4451-957f-54e9092c18ee"
   },
   "outputs": [],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jK8gPnOvedAV"
   },
   "source": [
    "In most cases this is fine, but sometimes you may want to manage multiple independent graphs. You can do this by creating a new *`Graph`* and temporarily making it the default graph inside a *`with`* block, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5BHlEYEedAW",
    "outputId": "efc67b81-81b8-4fc2-b271-803a4e3a08fb"
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDAkUYzQedAY",
    "outputId": "343a940f-a060-49ae-e79b-7078e63bf07e"
   },
   "outputs": [],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpKnjipHedAa"
   },
   "source": [
    "Sometime the default graph could have duplicated nodes (variables). We can reset to clean the graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ijdO-fCpedAa"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ArA9fBcHedAd"
   },
   "source": [
    "<a id = \"4_2\"></a>\n",
    "\n",
    "## 4.2 Operations (nodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ieeqmr4edAd"
   },
   "source": [
    "For many numpy operations, you can find their TensorFlow counterparts, such as `tf.add` for `+` and `tf.abs` for `np.abs`. You can also define your own operations (See [here](https://www.tensorflow.org/extend/adding_an_op)). Below we try to understand the less intuitive types of TensorFlow operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cBVvSH9edAf"
   },
   "source": [
    "#### Constants, Sequences, and Random Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvlCe-mNedAf"
   },
   "source": [
    "One simple type of TensorFlow operations (ops) are to create constant and random tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kE3RqDN2edAg"
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    op1 = tf.constant(5)\n",
    "    c = tf.add(op1, 1,  name='addition') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-euryrNmedAj",
    "outputId": "85f5bd02-b9bf-4250-fb89-92f72c82ebab"
   },
   "outputs": [],
   "source": [
    "print(g.get_operations())\n",
    "\n",
    "\n",
    "writer.reopen()\n",
    "writer.add_graph(g)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axVIuWPnedAm"
   },
   "source": [
    "You can view the graph in TensorBoard. As you can see, `tf.add` automatically converted the `1` to a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tn5XDMvtedAn"
   },
   "source": [
    "Now let's add a random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8n4j8q1edAo"
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    w = tf.random_normal(shape=[3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cZG5g6JedAq"
   },
   "outputs": [],
   "source": [
    "writer.add_graph(g)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyUoOkPMedAt"
   },
   "source": [
    "From TensorBoard, you can see this actually created a subgraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV15ViGuedAt"
   },
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4-JqFtAedAx"
   },
   "source": [
    "A TensorFlow variable is not to be confused with a Python variable. According to the TensorFlow documentation, *a variable maintains state in the graph across calls to run()*. As we will see later, all node values are dropped between graph runs, except variable values. Variables are used to keep the estimates for model parameters and they need to survive across multiple interactions of the model training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pySSpKYSedAx"
   },
   "source": [
    "We have seen how a variable can be created using the `tf.Variable()` constructor function. They can also be created using the `tf.get_variable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4MKuw6NRedAy"
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    v1 = tf.Variable(5)\n",
    "    v2 = tf.get_variable(\"another_variable\", initializer=tf.constant(5))\n",
    "    \n",
    "writer.add_graph(g)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o-N6RANedA0"
   },
   "source": [
    "Like a random value, a variable is also mapped to a subgraph in TensorBoard. Can you spot the differences between `v1` and `v2` subgraphs? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLZiFFogedA0"
   },
   "source": [
    "You probably already noticed that every variable needs an intializer; we will discuss this later. You can find more about TensorFlow variables [here](https://www.tensorflow.org/guide/variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rn0EnQ6redA1"
   },
   "source": [
    "#### Placehoder\n",
    "\n",
    "Suppose that you are evaluating a function *`y`* that takes an input *`x`*. You want to do this many times and change the input *`x`* each time (as in an iterative algorithm when we want to replace the input data at every iteration). Note that *`x`* cannot be a variable, as a variable can be initialised only once. The simplest way to do this is to use *`placeholder`* nodes. \n",
    "\n",
    "These nodes are special because they don’t actually perform any computation, they\n",
    "just output the data you tell them to output at runtime. They are typically used to pass the training data to TensorFlow during training, using the `feed_dict` parameter. \n",
    "\n",
    "Let's look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0eXEm6oedA1"
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y = x + 2\n",
    "    \n",
    "writer.add_graph(g)\n",
    "writer.flush()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSIzXut6edA3",
    "outputId": "0b029fcf-b176-44b2-f6b3-f3d76d4f3d42"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(y.eval(feed_dict={x: np.ones([1, 3])}))  #  feed 1x3 array \n",
    "    print(y.eval(feed_dict={x: np.zeros([2, 3])})) #  feed 2x3 array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4QIV49qedA5"
   },
   "source": [
    "If you don’t specify a value at runtime for a placeholder, you get an exception. Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8cXAHoPedA6",
    "outputId": "c5799a6e-ae72-487c-b374-4eb163aee06b"
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(y.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4jxOw6x2edA8"
   },
   "source": [
    "<a id = \"4_3\"></a>\n",
    "\n",
    "## 4.3 Tensors (edges) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eY8jkGwNedA9"
   },
   "source": [
    "Tensor is similar to numpy ndarray, and has both a type and a shape. It carries the dataflow between two nodes. You can find more information about tensors [here](https://www.tensorflow.org/guide/tensors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BHTK04PedA9"
   },
   "source": [
    "# Part 5. More about the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyLZ6eaiedA-"
   },
   "source": [
    "As we have seen, a TensorFlow graph has to run in a session. A session represents a C++ runtime. Normally, you execute a computation by calling `tf.Session.run` with one or more nodes in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvLM2LFGedA-"
   },
   "source": [
    "<a id = \"5_1\"></a>\n",
    "\n",
    "## 5.1 Lifecycle of a node value\n",
    "\n",
    "When you evaluate a node, TensorFlow automatically determines the set of nodes that it depends on and it evaluates these nodes first. Let's look at the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JdgG8bWpedA_",
    "outputId": "3d5a7817-de0d-49b9-afa9-f616e434fc26"
   },
   "outputs": [],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  # 10\n",
    "    print(z.eval())  # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qO0sNSv_edBB"
   },
   "source": [
    "The code evaluates *`y`* and *`z`*. For *`y`*, TensorFlow automatically detects that *`y`* depends on *`x`*, which depends on *`w`*, so it first evaluates *`w`*, then *`x`*, and then *`y`*. The schedule is: *`w -> x -> y`*. Likewise, the order for evaluating *`z`* is: *`w -> x -> z`*. It is important to note that it will ***not reuse*** the result of the previous evaluation of *`w`* and *`x`*. In short, the preceding code evaluates *`w`* and *`x`* ***twice***.<br>\n",
    "\n",
    "All node values are dropped between graph runs, except variable values, which are maintained by the session across graph runs. A variable starts its life when its initializer is run, and it ends when the session is closed.\n",
    "\n",
    "If you want to evaluate *`y`* and *`z`* more efficiently, i.e., without evaluating *`w`* and *`x`* twice as in the previous code, you must ask TensorFlow to simultaneously evaluate both *`y`* and *`z`* in just one graph run as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQfywF2wedBB",
    "outputId": "90836f29-3be4-4044-f194-f32ff9955711"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)  # 10\n",
    "    print(z_val)  # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8mNF_PNedBD"
   },
   "source": [
    "Sometimes, we will have two **independent** operations (ops) but you’d like to specify which operation (op) should be run **first**. You can create context manager that specifies control dependencies for all operations constructed within the context. For example, the following codes call for an increment of *`global_step`* each time we compute *`learning_rate`*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTS-z7vvedBE",
    "outputId": "1168e616-5730-45df-8a68-d929d55fef80"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "starter_lr = 1.\n",
    "decay_rate = 0.9\n",
    "global_step = tf.Variable(0., name = \"global_step\")\n",
    "incr = tf.assign(global_step, global_step + 1, name = \"incr\")\n",
    "\n",
    "\n",
    "with tf.control_dependencies([incr]):\n",
    "    learning_rate = tf.multiply(starter_lr, tf.pow(decay_rate, global_step), name = \"update_lr\")\n",
    "\n",
    "\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()  \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    global_step.initializer.run()\n",
    "    for i in range(5):\n",
    "        print('Global Step %d: Learning rate = %f' % ( global_step.eval(), learning_rate.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nETQ1qjedBG"
   },
   "source": [
    "**Without** controlling dependences: *`global_step`* will stay at `0.0`, and *`learning_rate`* will be `1.0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn0Lx3oKedBH",
    "outputId": "2c33f78c-b3f4-476e-c425-3adf74f28629"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "starter_lr = 1.\n",
    "decay_rate = 0.9\n",
    "global_step = tf.Variable(0., trainable=0)\n",
    "incr = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "learning_rate = starter_lr * tf.pow(decay_rate, global_step)\n",
    "\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()  \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    global_step.initializer.run()\n",
    "    for i in range(5):\n",
    "        print('Global step %d: Learning rate = %f' % (global_step.eval(), learning_rate.eval()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "enc107MoedBJ"
   },
   "source": [
    "Having `with tf.control_dependencies([incr]):` is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hgtk10-RedBK",
    "outputId": "f522f564-6cf1-49d3-b6d5-5ede0f6d4198"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "starter_lr = 1.\n",
    "decay_rate = 0.9\n",
    "global_step = tf.Variable(0., trainable=0)\n",
    "incr = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "learning_rate = starter_lr * tf.pow(decay_rate, global_step)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    global_step.initializer.run()\n",
    "    for i in range(5):\n",
    "        incr.eval()\n",
    "        print('Global step %d: Learning rate = %f' % (global_step.eval(), learning_rate.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "TcQTqbgeedBN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReOhKWr5edBO"
   },
   "source": [
    "* **Global variables initialization**: Instead of manually running the initializer for every single variable, you can use the *`global_variables_initializer()`* function, and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rp6GlkbPedBO",
    "outputId": "09199299-934a-42f7-aa6c-7f250ac8a4d6"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()  # prepare an init node\n",
    "with tf.Session() as sess:\n",
    "    init.run()  # actually initialize all the variables\n",
    "    result = global_step.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRvIXpkQedBQ"
   },
   "source": [
    "<a id = \"5_2\"></a>\n",
    "\n",
    "## 5.2 Save and restore models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIcDNnJfedBQ"
   },
   "source": [
    "Once you have trained your model, you should save its parameters to disk so that you can come back to it whenever you want, use it in another program, compare it to other models, and so on. Moreover, you probably want to save checkpoints at regular intervals during training so that if your computer crashes or encounters power-outage during training you can continue from the last checkpoint rather than start over from scratch.\n",
    "\n",
    "You might get into error if the folder path `models/example01` does not exist. You can create this folder in the directory containing this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bM3iLdlxedBR"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "theta = tf.Variable(tf.zeros([5]), name='theta')\n",
    "train_op = tf.assign(theta, theta + 1.)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d78hng7TedBT",
    "outputId": "38a144b8-0fec-48d6-847f-08ff56fd9113"
   },
   "outputs": [],
   "source": [
    "n_epochs = 201\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(train_op)\n",
    "        if (epoch) %100 == 0:  # checkpoint every 100 epochs\n",
    "            saver.save(sess, \"models/example01/save_and_restore.ckpt\")\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcytGLpoedBV"
   },
   "source": [
    "Restoring a model is just as easy: you create a `Saver` at the end of the construction phase just like before, but then at the beginning of the execution phase, instead of initializing the variables using the `init` node, you call the `restore()` method of the `Saver` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJdmvm7gedBW",
    "outputId": "d203394a-5f17-439f-d139-f37da85c99db"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "theta = tf.Variable(tf.zeros([5]), name='theta')\n",
    "train_op = tf.assign(theta, theta + 1.)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 200\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"models/example01/save_and_restore.ckpt\")\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(train_op)\n",
    "        if (epoch + 1) % 100 == 0:  # checkpoint every 100 epochs\n",
    "            saver.save(sess, \"models/example01/save_and_restore_cont.ckpt\")\n",
    "        \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjEWW59_edBY"
   },
   "source": [
    "After restoring and training for another 200 steps, best_theta is now [400.  400.  400.  400.  400.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7i2YwQhRedBY"
   },
   "source": [
    "<a id = \"5_3\"></a>\n",
    "\n",
    "## 5.3 Visualize learning curves in TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JN645EIedBY"
   },
   "source": [
    "Normally, we rely on the `print()` function and `matplotlib` to visualize progress during training. There is a better way, i.e., using TensorBoard. If you feed it some training stats, it will display nice interactive visualizations of\n",
    "these stats in your web browser (e.g., learning curves). You can also provide it the graph’s definition and\n",
    "it will give you a great interface to browse through it. This is very useful to identify errors in the graph, to\n",
    "find bottlenecks, and so on. Let's visualize learning rate and global step in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bc_PbX0oedBZ"
   },
   "outputs": [],
   "source": [
    "# construction\n",
    "tf.reset_default_graph()\n",
    "\n",
    "starter_lr = 1.\n",
    "decay_rate = 0.9\n",
    "global_step = tf.Variable(0., trainable=0)\n",
    "incr = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "with tf.control_dependencies([incr]):\n",
    "    learning_rate = starter_lr * tf.pow(decay_rate, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTn1rJBmedBa"
   },
   "source": [
    "Here, we construct the graph as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izSHP8F7edBb"
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('learning_rate', learning_rate)\n",
    "tf.summary.scalar('global_step', global_step)\n",
    "merged = tf.summary.merge_all() # Merges all summaries collected in the default graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HN8z1LPledBc"
   },
   "source": [
    "The first two lines create two summary *`ops`* in the graph that will evaluate the *`learning_rate`* and *`global_step`* value and write them to a TensorBoard compatible binary log string called a summary. The third line creates a node that merges all summaries collected in the default graph. In the execution phase, you'll need to evaluate the merged node regularly during training (e.g., every 10 mini-batches). This will output a summary that you can then write to the events file using the *`file_writer`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gWzH9FghedBc"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "logdir = \"tf_logs/example01/model-at-{}\".format(time.strftime('%Y-%m-%d_%H.%M.%S'))\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieIohPxcedBe"
   },
   "source": [
    "You need to use a different log directory every time you run your program, or else TensorBoard will merge stats from different runs, which will mess up the visualizations. The simplest solution for this is to include a timestamp in the log directory name. Now's the execution phase:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGCsHLmAedBe"
   },
   "source": [
    "The first line creates a node in the graph that will evaluate the *MSE* value and write it to a TensorBoard compatible binary log string called a summary. Then you need to update the execution phase to evaluate the *`mse_summary`* node regularly during training\n",
    "(e.g., every 10 mini-batches). This will output a summary that you can then write to the events file using\n",
    "the *`file_writer`*. Here is the updated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1Vc6HjQedBf"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    global_step.initializer.run()\n",
    "    for i in range(50):\n",
    "        merged_ = merged.eval()\n",
    "        file_writer.add_summary(merged_, i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84_9nhH5edBg"
   },
   "source": [
    "<img src=\"imgs/warning.png\" width=20, align=\"left\"></img> In actual Deep Learning implementation logging training stats at every single training step, as this would significantly slow down training. Instead, you should log 200 iterations for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9rvJxxFSedBh"
   },
   "source": [
    "Finally, you want to close the FileWriter at the end of the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYWqNFOPedBi"
   },
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E029Z_C6edBj"
   },
   "source": [
    "Great! Now it’s time to fire up the TensorBoard server. You need to activate your virtual environment\n",
    "if you created one, then start the server by running the *`tensorboard`* command, pointing it to the root log\n",
    "directory. This starts the TensorBoard web server, listening on port 6006 (which is “goog” written upside\n",
    "down :) )\n",
    "Next open a browser and go to http://0.0.0.0:6006/ (or http://localhost:6006/). Welcome to\n",
    "TensorBoard! In the Scalars tab, you'll see *`global_step`* and *`learning_rate`*:\n",
    "\n",
    "<img src='imgs/learning_rate.png?raw=1' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtioCy6HedBk"
   },
   "source": [
    "# Part 6. Name Scopes\n",
    "This section is more advanced. You may want to revisit it when you become more comfortable with TensorFlow.\n",
    "\n",
    "When dealing with more complex models such as neural networks, the graph can easily become cluttered with thousands of nodes. To avoid this, you can create name scopes to group related nodes. The following code defines two operations sum and product under two scopes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17p7t8amedBl"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.placeholder(tf.float32, shape=(), name='a')\n",
    "b = tf.placeholder(tf.float32, shape=(), name='b')\n",
    "\n",
    "with tf.name_scope('calc'):\n",
    "    c = a + b\n",
    "    d = a + b\n",
    "    e = a * b\n",
    "    f = tf.add(a, b, name='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXaTwZ4redBn"
   },
   "outputs": [],
   "source": [
    "print(c.op.name)\n",
    "print(d.op.name)\n",
    "print(e.op.name)\n",
    "print(f.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0bQF4bFedBo"
   },
   "source": [
    "The name of each op defined within the scope is now prefixed with \"calc/\". `c`, `d`, and `e` get generic names while `d` gets the name 'sum' that we passed into the operation. Note that `d` and `c` has the same generic name *`add`* but `d` is defined created later so it get the name *`calc/add_1`*.\n",
    "\n",
    "For more detail about *`tf.name_scope`*, read: https://www.tensorflow.org/api_docs/python/tf/Graph#name_scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kk-1qtb0edBp"
   },
   "source": [
    " For a more complete introduction of the TensorFlow compution graph, please see the [official guide](https://www.tensorflow.org/guide/graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQ4nCaiiedBp"
   },
   "source": [
    "### Modularity\n",
    "\n",
    "Suppose you want to create a graph that adds the output of two [rectified linear units (ReLU)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks). A ReLU computes a linear function of the inputs, and outputs the result if it is positive, and 0 otherwise, as shown in the following equation:\n",
    "\n",
    "$$h_{\\mathbf{W}, \\mathbf{b}}(\\mathbf{x})=\\max(\\mathbf{W}^T\\mathbf{x} + \\mathbf{b}, 0)$$\n",
    "\n",
    "The following does the job but quit repetitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVzHqWqUedBq"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "\n",
    "b1 = tf.Variable(0.0, name=\"bias1\")\n",
    "b2 = tf.Variable(0.0, name=\"bias2\")\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
    "relu2 = tf.maximum(z1, 0., name=\"relu2\")\n",
    "\n",
    "output = tf.add(relu1, relu2, name=\"output\")\n",
    "\n",
    "logdir = 'tf_logs/example01/modularity'\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3MtSEhxedBs"
   },
   "source": [
    "<img src='imgs/graph01.PNG?raw=1' width=500>\n",
    "\n",
    "The graph looks unorganized and hard to follow! Suppose we want to creates many ReLUs and outputs their sum, the graph is very messy and is hard to follow.\n",
    "\n",
    "The following code creates five ReLUs and outputs their sum (note that *`add_n()`* creates an operation that will compute the sum of a list of tensors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V25qEkqxedBs"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"linear\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "logdir = 'tf_logs/example01/modularity_clean'\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUfvxDmNedBt"
   },
   "source": [
    "Note that when you create a node, TensorFlow checks whether its name already exists, and if it does, TensorFlow appends an underscore followed by an index to make the name unique. So the first ReLU contains nodes named \"weights\", \"bias\", \"z\", and \"relu\" (plus many more nodes with their default name, such as \"MatMul\"); the second ReLU contains nodes named \"weights_1\", \"bias_1\", and so on; the third ReLU contains nodes named \"weights_2\", \"bias_2\", and so on. TensorBoard identifies such series and collapses them together to reduce clutter.\n",
    "\n",
    "<img src='imgs/graph02.PNG?raw=1' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwSslqe-edBu"
   },
   "source": [
    "Let's try using name scopes to see if we can make the graph clearer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GH0aWCytedBv"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope('relu'):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"linear\")\n",
    "        return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "logdir = 'tf_logs/example01/modularity_clearer'\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVKxnKL9edBw"
   },
   "source": [
    "<img src='imgs/graph03.PNG?raw=1' width=600>\n",
    "\n",
    "The graph now looks much clearer. Notice that TensorFlow also gives the name scopes unique names by appending _1, _2, and so on. If we expand one of the relu, we'll see:\n",
    "\n",
    "<img src='imgs/graph04.PNG?raw=1' width=600>\n",
    "\n",
    "<img src=\"images/note.gif\" width=\"20\", align=\"left\"></img> &nbsp; Weights and bias are now within the name_scope relu2 so we don't see _2 appended to the name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLWUJeHCedBx"
   },
   "source": [
    "### Sharing Variables\n",
    "\n",
    "Suppose you want to control the ReLU threshold (currently hardcoded to 0) using a shared threshold variable for all ReLUs. You can use the *`get_variable()`* function to create the shared variable if it does not exist yet, or reuse it if it already exists. The desired behavior (creating or reusing) is controlled by an attribute of the current *`variable_scope()`*. For example, the following code will create a variable named *`\"relu/threshold\"`* (as a scalar, since *`shape=()`*, and using\n",
    "0.0 as the initial value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_GqdAMDedBy"
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqsRWRvuedBz"
   },
   "source": [
    "<img src=\"images/warning.png\" width=\"40\", align=\"left\"></img> If the variable has already been created by an earlier call to *`get_variable()`*, this code will raise an exception. This behavior prevents reusing variables by mistake. If you want to reuse a variable, you need to explicitly say so by setting the variable scope’s reuse attribute to *`True`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sRwyU6jedB0"
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\", reuse=True):\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmV7HYtMedB3"
   },
   "source": [
    "This code will fetch the existing *`\"relu/threshold\"`* variable, or raise an exception if it does not exist or if it was not created using *`get_variable()`*. Alternatively, you can set the reuse attribute to *`True`* inside the block by calling the scope’s *`reuse_variables()`* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vse74xYedB3"
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\") as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wf0rMDdvedB5"
   },
   "source": [
    "Now you have all the pieces you need to make the *`relu()`* function access the threshold variable without having to pass it as a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rTtnZT_edB5"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"linear\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "with tf.variable_scope(\"relu\"): # create the variable\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "logdir = 'tf_logs/example01/customized_relu'\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GV0AzYNBedB7"
   },
   "source": [
    "<img src='imgs/graph05.PNG?raw=1' width=800>\n",
    "\n",
    "This code first defines the *`relu()`* function, then creates the *`relu/threshold`* variable (as a scalar that will later be initialized to 0.0) and builds five ReLUs by calling the *`relu()`* function. The *`relu()`* function reuses the *`relu/threshold`* variable, and creates the other ReLU nodes. Therefore, we see the \"scalar\" connections between the first created ReLU and the other 5 ReLUs, meaning that 5 ReLUs reuse the threshold scalar from the first created ReLU.\n",
    "\n",
    "To avoid creating the first unused ReLU. We can pass the reuse argument to the function *`relu()`*. We'll set *`reuse = True`* when after the first ReLU is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeeOvi5FedB7"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X, reuse=False):\n",
    "    with tf.variable_scope('relu') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"linear\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "relus = [relu(X, reuse=i>0) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "logdir = 'tf_logs/example01/customized_relu2'\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMJFCkE8edB-"
   },
   "source": [
    "<img src='imgs/graph06.PNG?raw=1' width=600>\n",
    "\n",
    "This time, exactly 5 ReLUs are created, with *`ReLU_[1,2,3,4]`* reuse the threshold scalar from the first ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <div  style=\"text-align:center\">**THE END**</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "AR0-1RfRedAK",
    "mTENUNAaedAM",
    "c8cCZjN6edAS",
    "ArA9fBcHedAd",
    "9cBVvSH9edAf",
    "HV15ViGuedAt",
    "Rn0EnQ6redA1",
    "4jxOw6x2edA8",
    "DvLM2LFGedA-",
    "eRvIXpkQedBQ",
    "7i2YwQhRedBY",
    "eQ4nCaiiedBp",
    "lLWUJeHCedBx"
   ],
   "include_colab_link": true,
   "name": "“CYB80001-Week2C-TensorFlow-I.ipynb”的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
